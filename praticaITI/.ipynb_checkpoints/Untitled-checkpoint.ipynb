{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guía 3: ITI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Se tiene un archivo con 10 caracteres en total formado por tres caracteres distintos (ej: ABC). De todos los archivos posibles con estas características mostrar el archivo de máxima entropía que se pueda comprimir mejor usando LZ77. No es necesario comprimir el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recuerdo que LZ77 busca repeticiones de una longitud finita, separando por ceros a los caracteres planos y en representando repeticiones en formato << 1, longitud, desfasaje >>\n",
    "\n",
    "##### Ademas por ser un compresor por repetición si me piden máxima entropia, ésto seria que las probabilidades de cada carácter dentro de nuestro archivo sean parejas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"xlogx.png\" alt=\"xlogx\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### (1) Propongo: AABBCAABBC\n",
    "\n",
    "###### (1) Comprimido: 0A 0A 0B 0B 0C 155\n",
    "\n",
    "###### (2) Propongo: ABCABCABCA\n",
    "\n",
    "###### (2) Comprimido: 0A 0B 0C 133 133 0A\n",
    "\n",
    "###### ------------------------------\n",
    "\n",
    "###### Me quedo con (2), pues posee mejor distribuciond de las probabilidades de cada caracter, mas allá de que el comprimido sea distinto, entonces \n",
    "\n",
    "#### Propongo: ABCABCABCX con X = A / B / C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explique en que casos sería una buena idea usar un compresor aritmético estático de orden 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Por ser de orden 3: Seria conveniente en aquellos casos donde tiene sentido estudiar que caracter puede suceder en el contexto de los 3 caracteres anteriores\n",
    "\n",
    "##### Por ser aritmetico (estadístico): Queremos minimizar la entropía, es decir que los contextos nos proporciones probabiliades determinísiticas para el caracter siguiente.\n",
    "\n",
    "##### Sería una buena idea entonces, para casos donde los contextos de 3 caracteres sean útiles para predecir el proximo, de ser posible, con probabilidad total.\n",
    "\n",
    "##### <mark>Ejemplo concreto: Consultar</mark>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tenemos un compresor aritmético dinámico de orden 0 que trabaja procesando bit por bit. Si comprimimos un archivo que está formado por una serie de 1000 bits en 1 y luego dos bits en 0. ¿cuántos bits ocupará el archivo comprimido?\n",
    "\n",
    "##### 11111111111111.....100\n",
    "\n",
    "##### <mark>Consultar</mark>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Verdadero o falso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. La entropia es una aproximacion de cuanto se puede comprimir, dado que no podemos alcular cuanto se puede comprimir un string\n",
    "\n",
    "##### Verdadero - La entropía es una medida estadística del \"desorden\", nos da la pauta de que tan ordenado está un archivo, de manera que los archivos aleatorios (aquellos donde es dificil la compresión) maximizan la entropía, consecuentemente, los que contengan elementos con probabilidad cercana a 1 (modelo de fuente determinísitca) la minimizan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Una forma posible de comprimir un stream de datos es utilizar un huffman estático.\n",
    "\n",
    "##### Falso - Pues Huffman estático basa su compresión en recorrer el archivo por completo en una primer pasada cuenta la cantidad de veces que aparece cada mensaje, para en una segunda genera los codigos a partir de la frecuencia de cada uno de ellos. En un stream de datos, no podría nunca terminar de calcular el la cantidad de veces que aparece cada mensaje (pues nunca dejarían de llegar datos). Existe para estas aplicaciones, el Huffman dinámico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. La entropia puede utilizarse para construir clasificadores de texto.\n",
    "\n",
    "##### <mark>Que es un clasificador</mark> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Un compresor estadistico estático comprime siempre mejor que un compresor estadístico dinámico.\n",
    "\n",
    "Si, pues el estático puede conocer el archivo entero al momento de calcular su entropía. <mark> Consultar </mark> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Podemos determinar la longitud final del archivo comprimido utilizando huffman estático de orden 1, calculando la entropía y multiplicándola por la cantidad de caracteres del archivo.\n",
    "\n",
    "\n",
    "##### FALSO,  contraejemplo para: \n",
    "\n",
    " <mark>Consultar si vale para Huffman estatico de orden 0</mark> \n",
    "\n",
    "\n",
    "AAAABBCDEF\n",
    "\n",
    "A = 4/10  \n",
    "B = 2/10  \n",
    "C = 1/10  \n",
    "D = 1/10  \n",
    "E = 1/10  \n",
    "F = 1/10\n",
    "\n",
    "_______________________________________\n",
    "\n",
    "HUFFMAN ORDEN 1\n",
    "\n",
    "Cont A: A = 3, B = 1  \n",
    "Cont B: B = 1, C = 1  \n",
    "Cont C: D = 1  \n",
    "Cont D: E = 1  \n",
    "Cont E: F = 1  \n",
    "\n",
    "Primer digito igual  \n",
    "A -> A  \n",
    "                                                  1      0  \n",
    "contA(A) necesito arbol huffman                A (3)    B(1)     \n",
    "AA -> A1  \n",
    "\n",
    "contA(A)  \n",
    "AAA -> A11  \n",
    "\n",
    "contA(A)  \n",
    "AAAA -> A111  \n",
    "\n",
    "contA(B) está implicito porque ya gasté todas las A  \n",
    "AAAAB -> A111  \n",
    "                                              1      0  \n",
    "contB(B) neceisto arbol huffman             B(1)    C(1)  \n",
    "AAAABB-> A1111  \n",
    "\n",
    "contB(C) está implicito porque ya gasté la B  \n",
    "AAAABBC -> A1111  \n",
    "\n",
    "contC(D) está implicito prob = 1  \n",
    "AAAABBCD -> A1111  \n",
    "\n",
    "contD(E) está implicito prob = 1  \n",
    "AAAABBCDE -> A1111  \n",
    "\n",
    "contE(F) está implicito prob = 1  \n",
    "AAAABBCDEF -> A1111  \n",
    "\n",
    "\n",
    "ARCHIVO COMPRIMIDO : Tabla freq + A1111   \n",
    "Longitud(A1111) = 5  \n",
    "_______________________________________\n",
    "\n",
    "ENTROPIA\n",
    "\n",
    "H = 4/10 * log2(4/10) + 2/10 * log2(2/10) + 4 * 1/10 * log2(1/10) = 2.3219\n",
    "\n",
    "H * cantCaracteres(10) = 23.219 = 24\n",
    "\n",
    "ENTROPIA(arch) 24 != LONGCOMPRIMIDO(arch) 5\n",
    "\n",
    "Por lo tanto el postulado es falso\n",
    "_______________________________________\n",
    "\n",
    "HUFFMAN ORDEN 0\n",
    "\n",
    "\n",
    "A = 0\n",
    "B = 10\n",
    "C = 1100\n",
    "D = 1101\n",
    "E = 1110\n",
    "F = 1111\n",
    "\n",
    "0 0 0 0 10 10 1100 1101 1110 1111 #bits = 24\n",
    "\n",
    "________________________________________\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F. Tenemos 2 archivos, uno con longitud pequeña y el otro muy grande que se comprimen utilizando huffman estático de orden 5. Si observamos que tienen la mismas tablas de frecuencias podemos afirmar que el cociente entre el tamaño del archivo sin comprimir y el tamaño del archivo comprimido será similar.\n",
    "\n",
    "##### H Estatico de orden 5: Estudia contexto en base a los 5 caracteres previos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G. Todo archivo con complejidad de kolmogorov baja tendrá una entropía de Shannon baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H. Es imposible que un archivo comprimido mediante huffman estático de orden 1 iguale la máxima compresión dada por la entropía del mismo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
